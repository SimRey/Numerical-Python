{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> Unconstrained optimization</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate  Optimization\n",
    "\n",
    "Optimization of a function that only depends on a single variable is relatively easy. In addition to the analytical approach of seeking the roots of the derivative of the function, we can employ techniques that are similar to the root-finding methods for univariate functions, namely, bracketing methods and Newton’s method. \n",
    "\n",
    "In SciPy’s optimize module, the brent function is such a hybrid method, and it is generally the preferred method for optimization of univariate functions with SciPy. This method is a variant of the golden section search method that uses inverse parabolic interpolation to obtain faster convergence. Instead of calling the optimize.golden and optimize.brent functions directly, it is convenient to use the unified interface function optimize.minimize_scalar, which dispatches to the optimize.golden and optimize.brent functions depending on the value of the method keyword argument, where the currently allowed options are 'Golden', 'Brent', or 'Bounded'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize as opt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sympy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** minimizing the area of a cylinder with a unit volume\n",
    "$$ f(r,h) = 2\\pi r^2 + 2\\pi rh$$\n",
    "Constrained by: $ g(r,h): \\pi r^2h = 1$\n",
    "\n",
    "Substituting $h = \\frac{1}{\\pi r^2}$ and writing the function in terms of r:\n",
    "$$ f(r) = 2\\pi r^2 + \\frac{2}{r}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum radius is 0.5419260772557135, giving an area of 5.535810445932086\n"
     ]
    }
   ],
   "source": [
    "# Numeric solving\n",
    "\n",
    "f = lambda r: 2 * np.pi * r ** 2 + 2 / r\n",
    "r_min = opt.minimize_scalar(f, bracket=(0.1, 4), method=\"Brent\")\n",
    "\n",
    "print(f\"The minimum radius is {r_min.x}, giving an area of {r_min.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "r_vals = np.linspace(0.1, 1.5, 100)\n",
    "\n",
    "plt.plot(r_vals, f(r_vals))\n",
    "plt.plot(r_min.x, r_min.fun, marker=\"*\", markeredgecolor=\"green\", markerfacecolor=\"red\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unconstrained Multivariate Optimization\n",
    "\n",
    "Multivariate optimization is significantly harder than the univariate optimization discussed in the previous section. In particular, the analytical approach of solving the nonlinear equations for roots of the gradient is rarely feasible in the multivariate case, and the bracketing scheme used in the golden search method is also not directly applicable. Instead we must resort to techniques that start at some point in the coordinate space and use different strategies to move toward a better approximation of the minimum point. The most basic approach of this type is to consider the gradient ∇f(x) of the objective function f(x) at a given point x. In general, the negative of the gradient, −∇f(x), always points in the direction in which the function f(x) decreases the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton method\n",
    "\n",
    "Newton’s method for multivariate optimization is a modification of the steepest descent method that can improve convergence. As in the univariate case, Newton’s method can be viewed as a local quadratic approximation of the function, which when minimized gives an iteration scheme. In the multivariate case, the iteration formula is $x_{k+1} = x_k - H^{-1}_f (x_k) \\nabla f (x_k)$, where compared to the steepest descent method, the gradient has been replaced with the gradient multiplied from the left with the inverse of Hessian matrix for the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1, x2 = sympy.symbols(\"x_1, x_2\")\n",
    "f_sym = (x1-1)**4 + 5 * (x2-1)**2- 2*x1*x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}- 2 x_{2} + 4 \\left(x_{1} - 1\\right)^{3}\\\\- 2 x_{1} + 10 x_{2} - 10\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[-2*x_2 + 4*(x_1 - 1)**3],\n",
       "[   -2*x_1 + 10*x_2 - 10]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fprime_sym = [f_sym.diff(x_) for x_ in (x1, x2)]\n",
    "sympy.Matrix(fprime_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}12 \\left(x_{1} - 1\\right)^{2} & -2\\\\-2 & 10\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[12*(x_1 - 1)**2, -2],\n",
       "[             -2, 10]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fhess_sym = [[f_sym.diff(x1_, x2_) for x1_ in (x1, x2)] for x2_ in (x1, x2)]\n",
    "sympy.Matrix(fhess_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectoryzing the expressions \n",
    "\n",
    "f_lmbda = sympy.lambdify((x1, x2), f_sym, 'numpy')\n",
    "fprime_lmbda = sympy.lambdify((x1, x2), fprime_sym, 'numpy')\n",
    "fhess_lmbda = sympy.lambdify((x1, x2), fhess_sym, 'numpy')\n",
    "\n",
    "\n",
    "def func_XY_to_X_Y(f):\n",
    "    \"\"\" Wrapper for f(X) -> f(X[0], X[1])\"\"\"\n",
    "    return lambda X: np.array(f(X[0], X[1]))\n",
    "\n",
    "\n",
    "f = func_XY_to_X_Y(f_lmbda)\n",
    "fprime = func_XY_to_X_Y(fprime_lmbda)\n",
    "fhess = func_XY_to_X_Y(fhess_lmbda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -3.867223\n",
      "         Iterations: 8\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "         Hessian evaluations: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.88292613, 1.37658523])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solving the problem\n",
    "x_opt = opt.fmin_ncg(f, (0, 0), fprime=fprime, fhess=fhess)\n",
    "x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quasi-Newton methods\n",
    "\n",
    "In practice, it may not always be possible to provide functions for evaluating both the gradient and the Hessian of the objective function, and often it is convenient with a solver that only requires function evaluations. For such cases, several methods exist to numerically estimate the gradient or the Hessian or both. Methods that approximate the Hessian are known as quasi-Newton methods, and there are also alternative iterative methods that completely avoid using the Hessian. Two popular methods are the Broyden-Fletcher-Goldfarb-Shanno (BFGS) and the conjugate gradient methods, which are implemented in SciPy as the functions optimize.fmin_bfgs and optimize.fmin_cg. The BFGS method is a quasi-Newton method that can gradually build up numerical estimates of the Hessian, and also the gradient, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -3.867223\n",
      "         Iterations: 9\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.88292644, 1.37658595])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt = opt.fmin_bfgs(f, (0, 0))\n",
    "x_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the number of function evaluations is even larger, but it is clearly convenient to not have to implement functions for the gradient and the Hessian.In general, the BFGS method is often a good first approach to try, in particular if neither the gradient nor the Hessian is known. If only the gradient is known, then the BFGS method is still the generally recommended method to use, although the conjugate gradient method is often a competitive alternative to the BFGS method. If both the gradient and the Hessian are known, then Newton’s method is the method with the fastest convergence in general. However, it should be noted that although the BFGS and the conjugate gradient methods theoretically have slower convergence than Newton’s method, they can sometimes offer improved stability and can therefore be preferable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: -3.8672228877100845\n",
      " hess_inv: array([[0.11091497, 0.02064493],\n",
      "       [0.02064493, 0.10048751]])\n",
      "      jac: array([1.57952309e-06, 6.82473183e-06])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 39\n",
      "      nit: 9\n",
      "     njev: 13\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([1.88292645, 1.37658596])\n"
     ]
    }
   ],
   "source": [
    "def func(var):\n",
    "    x1 = var[0]\n",
    "    x2 = var[1]\n",
    "    return (x1 - 1) ** 4 + 5 * (x2 - 1) ** 2 - 2 * x1 * x2\n",
    "\n",
    "\n",
    "x_opt = opt.minimize(func, [0, 0], method='BFGS')\n",
    "print(x_opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For problems with many local minima, this can easily lead to a situation when the solver easily gets stuck in a local minimum, even if a global minimum exists. Although there is no complete and general solution to this problem, a practical approach that can partially alleviate this problem is to use a brute force search over a coordinate grid to find a suitable starting point for an terative solver. At least this gives a systematic approach to find a global minimum within given coordinate ranges. In SciPy, the function optimize.brute can carry out such a systematic search. To illustrate this method, consider the problem of minimizing the function:\n",
    "$$ 4 sin(xπ) + 6sin(yπ)+(x− 1)^2+(y− 1)^2$$\n",
    "which has a large number of local minima. This can make it tricky to pick a suitable initial point for an iterative solver\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5, 1.5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(X):\n",
    "    x, y = X\n",
    "    fun = 4 * np.sin(np.pi * x) + 6 * np.sin(np.pi * y) + (x - 1)**2 + (y - 1)**2\n",
    "    return fun\n",
    "\n",
    "x_start = opt.brute(f, (slice(-3, 5, 0.5),  slice(-3, 5, 0.5)), finish=None)\n",
    "x_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -9.520229\n",
      "         Iterations: 4\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.47586906, 1.48365787])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_opt = opt.fmin_bfgs(f, x_start)\n",
    "x_opt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a9e06a1eee47c4abbed4ec8225ad91d78d9800d202b71b6b0a6e47016c6abd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
